
          <div class="myprojects">
            <h2>Projects</h2>

            <table style="width:100%;border:0px;border-spacing:25px;border-collapse:separate;margin-right:auto;margin-left:auto; font-family: Arial, sans-serif; font-size: 4px;"><tbody>

              <!-- INSTINCTIVE ROBOT CONTROL VIA HOLOLENS 2 -->
              <tr>
                <td width="40%" valign="middle" align="center">
                <img src="assets/img/mixedreality_wrapup.gif" alt="sym" width="90%" style="margin-top:10px;padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black">
                </td>

                <td width="60%" valign="middle">
                  <p><a href="mixedreality.html" id="mixedreality">
                  <div style="color: #003dc2;"><strong><b>Instinctive Robot Control via Hololens2</b></strong></div></a>
                  Team members:
                  Ivan Alberico,
                  <a href="https://www.linkedin.com/in/michael--baumgartner/?originalSubdomain=ch">Michael Baumgartner</a>,
                  <a href="https://www.linkedin.com/in/jonathan-becker-tech/">Jonathan Becker</a>,
                  <a href="https://www.linkedin.com/in/seif-ismail-143b53247/">Seif Ismail</a>
                  <br>
                  </p>

                  <p>              
                  <div class="project" id="mixedreality">
                    <a href="mixedreality.html" style="color: #2698BA;">Webpage</a> |
                    <a href="https://www.youtube.com/watch?v=YiZyG_5g66w" style="color: #2698BA;">Video</a> |
                    <a href="assets/pdf/mixedreality_report.pdf" style="color: #2698BA;">Report</a> |
                    <a href="https://github.com/MR-Instinctive-Robot-Control/Hand-Robot-Controller" style="color: #2698BA;">Code </a>
                  </div>
                  </p>

                  <p>
                    <div style="text-align: justify;">
                      Mixed reality interface on a Microsoft Hololens 2, with which the user is able to remotely 
                      control a robotic arm and perform basic assembly tasks using hand and eye tracking.
                    </div>
                  </p>
                            
              </td>
              </tr>

              <!-- PERCEPTION AND LEARNING FOR ROBOTICS PROJECT -->
              <tr>
                <td width="40%" valign="middle" align="center">
                <img src="assets/img/plr_cut.gif" alt="sym" width="90%" style="margin-top:10px;padding-top:0px;padding-bottom:0px;border-radius:25px;border:1px solid black">
                </td>

                <td width="60%" valign="middle">
                  <p><a href="plr.html" id="plr">
                  <div style="color: #003dc2;"><strong><b>Monocular Markerless 6D Pose Estimation of ANYmal</b></strong></div></a>
                    Team members:
                    Ivan Alberico,
                    <a href="https://tenhearts.github.io/">Kexin Shi</a>
                    <br>
                    Supervised by <a href="https://mavt.ethz.ch/people/person-detail.MjY0MDU2.TGlzdC81NTksLTE3MDY5NzgwMTc=.html">Jonas Frey</a>,
                     <a href="https://mavt.ethz.ch/people/person-detail.MjE4MDk1.TGlzdC81NTksLTE3MDY5NzgwMTc=.html">Victor Klemm</a>
                     and <a href="https://ethz.ch/en/the-eth-zurich/organisation/who-is-who/mavt/details.MTIxOTEx.TGlzdC8xOTEyLDEwNjE0ODE1NjU=.html">Marco Hutter</a>
                  </p>

                  <p>              
                  <div class="project" id="plr">
                    <a href="plr.html" style="color: #2698BA;">Webpage</a> |
                    <a href="assets/pdf/plr_poster.pdf" style="color: #2698BA;">Poster</a> |
                    <a href="https://www.youtube.com/watch?v=4saCcrD37qA" style="color: #2698BA;">Video</a> |
                    <a href="assets/pdf/plr_report.pdf" style="color: #2698BA;">Report</a> 
                    <!-- <a href="https://github.com/leggedrobotics/anymal_ar">Code (Open Soon)</a> -->
                  </div>
                  </p>

                  <p>
                    <div style="text-align: justify;">
                      An accurate toolbox for localization and pose estimation of <a href="https://www.anybotics.com/anymal-autonomous-legged-robot/">ANYmal</a> without 
                      external sources like depth cameras or QR codes.
                    </div>
                  </p>
                            
              </td>
              </tr>

              <!-- LEARNING TO GENERATE EVENTS USING SPIKING NEURAL NETWORKS -->
              <tr>
                <td width="40%" valign="middle" align="center">
                <img src="assets/img/semesterproject.gif" alt="sym" width="90%" style="margin-top:10px;padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black">
                </td>

                <td width="60%" valign="middle">
                  <p><a href="semesterproject.html" id="plr">
                  <div style="color: #003dc2;"><strong><b>Learning to Generate Events using Spiking Neural Networks</b></strong></div></a>
                    Supervised by <a href="https://danielgehrig18.github.io/">Daniel Gehrig</a>,
                     and <a href="https://rpg.ifi.uzh.ch/people_scaramuzza.html">Davide Scaramuzza</a>
                  </p>

                  <p>              
                  <div class="project" id="plr">
                    <a href="semesterproject.html" style="color: #2698BA;">Webpage</a> | 
                    <a href="assets/pdf/semesterthesis_report.pdf" style="color: #2698BA;">Report</a> 
                    <!-- <a href="https://github.com/leggedrobotics/anymal_ar">Code (Open Soon)</a> -->
                  </div>
                  </p>

                  <p>
                    <div style="text-align: justify;">
                      A learning-based solution that converts any existing video dataset recorded with 
                      conventional cameras to synthetic event data. 
                    </div>
                  </p>
                            
              </td>
              </tr>

              <!-- 3D VISION -->
              <tr>
                <td width="40%" valign="middle" align="center">
                <img src="assets/img/3dvision.gif" alt="sym" width="90%" style="margin-top:10px;padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black">
                </td>

                <td width="60%" valign="middle">
                  <p><a href="3dvision.html" id="3dvision">
                  <div style="color: #003dc2;"><strong><b>End-2-End Self-Supervised SLAM </b></strong></div></a>
                  Team members:
                  Ivan Alberico,
                  <a href="https://www.linkedin.com/in/akbar96/">Mian Akbar Shah</a>,
                  <a href="https://www.linkedin.com/in/selim-kaelin-947887172/">Selim Kaelin</a>,
                  <a href="https://www.linkedin.com/in/emilk-sempertegui-9b7719100/">Emilk Sempertegui</a>
                  <br>
                  </p>

                  <p>              
                  <div class="project" id="3dvision">
                    <a href="3dvision.html" style="color: #2698BA;">Webpage</a> |
                    <a href="assets/pdf/3DVision_report.pdf" style="color: #2698BA;">Report</a> |
                    <a href="https://github.com/ivanalberico/End-To-End-Self-Supervised-SLAM" style="color: #2698BA;">Code </a>
                  </div>
                  </p>

                  <p>
                    <div style="text-align: justify;">
                      An online self-supervised SLAM pipeline for real-time dense reconstruction, with an online adaption module to 
                      boost performance on indoor scenes.
                    </div>
                  </p>
                            
              </td>
              </tr>

              <!-- DEEP LEARNING FOR AUTONOMOUS DRIVING PROJECT -->
              <tr>
                <td width="40%" valign="middle" align="center">
                <img src="assets/img/dlad_cover.png" alt="sym" width="90%" style="margin-top:10px;padding-top:0px;padding-bottom:0px;">
                </td>

                <td width="60%" valign="middle">
                  <p><a href="dlad.html" id="dlad">
                  <div style="color: #003dc2;"><strong><b>Multi-task Learning for Autonomous Driving</b></strong></div></a>
                  Team members:
                  Ivan Alberico,
                  <a href="https://www.linkedin.com/in/nicolaloi/">Nicola Loi</a>
                  </p>

                  <p>              
                  <div class="project" id="dlad">
                    <a href="dlad.html" style="color: #2698BA;">Webpage</a> |
                    <a href="https://github.com/ivanalberico/Deep-Learning-for-Autonomous-Driving-ETH" style="color: #2698BA;">Github</a>
                  </div>
                  </p>
                    
                  <p>
                    <div style="text-align: justify;">
                      Multi-task Learning for semantic segmentation, depth estimation and 3D object detection for autonomous driving scenes. 
                    </div>
                  </p>
                            
              </td>
              </tr>

              <!-- PLANNING AND DECISION MAKING FOR AUTONOMOUS ROBOTS -->
              <tr>
                <td width="40%" valign="middle" align="center">
                <img src="assets/img/pdmar.gif" alt="sym" width="90%" style="margin-top:10px;padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black">
                </td>

                <td width="60%" valign="middle">
                  <p><a href="pdmar.html" id="pdmar">
                  <div style="color: #003dc2;"><strong><b>Planning and Decision Making for Autonomous Robots</b></strong></div></a>
                  Team members:
                  Ivan Alberico,
                  <a href="https://www.linkedin.com/in/nicolaloi/">Nicola Loi</a>
                  </p>

                  <p>              
                  <div class="project" id="pdmar">
                    <a href="pdmar.html" style="color: #2698BA;">Webpage</a> |
                    <a href="https://github.com/ivanalberico/Planning-and-Decision-Making-for-Autonomous-Robots-ETH" style="color: #2698BA;">Github</a>
                  </div>
                  </p>      
                    
                  <p>
                    <div style="text-align: justify;">
                      Implementation of a path planning pipeline in a dynamic environment. Global path planning, 
                      local path planning, and obstacle avoidance for navigating a spacecraft to a goal region 
                      while avoiding static and dynamic asteroids.
                    </div>
                  </p>
                            
              </td>
              </tr>

              <!-- VIRTUAL REALITY I - SKATER BLOB -->
              <tr>
                <td width="40%" valign="middle" align="center">
                <img src="assets/img/skaterblob.gif" alt="sym" width="90%" style="margin-top:10px;padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black">
                </td>

                <td width="60%" valign="middle">
                  <p><a href="skaterblob.html" id="skaterblob">
                  <div style="color: #003dc2;"><strong><b>Skater Blob game on Unity</b></strong></div></a>
                  Team members:
                  Ivan Alberico,
                  <a href="https://www.linkedin.com/in/adrian-hartmann/">Adrian Hartmann</a>
                  </p>

                  <p>              
                    <div class="project" id="skaterblob">
                      <a href="skaterblob.html" style="color: #2698BA;">Webpage</a> |
                      <a href="https://github.com/ivanalberico/Virtual-Reality1-ETH-SkaterBlobGame" style="color: #2698BA;">Github</a>
                    </div>
                  </p>  
                    
                  <p>
                    <div style="text-align: justify;">
                      Implementation of a skateboarding game using Unity3D and Blender. Every aspect, from crafting 
                      the main 3D models to animating characters and designing the game's logic and levels, was 
                      meticulously implemented from scratch.
                    </div>
                  </p>
                            
              </td>
              </tr>

              <!-- ADMITTANCE CONTROLLER -->
              <tr>
                <td width="40%" valign="middle" align="center">
                <img src="assets/img/pHRI_hapticpaddle.jpg" alt="sym" width="90%" style="margin-top:10px;padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black">
                </td>

                <td width="60%" valign="middle">
                  <p><a href="pHRI.html" id="phri">
                  <div style="color: #003dc2;"><strong><b>Admittance Controller on Haptic Paddle</b></strong></div></a>
                  Team members:
                  Ivan Alberico,
                  <a href="https://www.linkedin.com/in/giulio-schiavi-439174221/">Giulio Schiavi</a>
                  </p>

                  <p>              
                    <div class="project" id="phri">
                      <a href="pHRI.html" style="color: #2698BA;">Webpage</a> |
                      <a href="https://github.com/ivanalberico/Virtual-Reality1-ETH-SkaterBlobGame" style="color: #2698BA;">Github</a>
                    </div>
                  </p>  

                  <p>
                    <div style="text-align: justify;">
                      Implementation of an admittance controller with inner position/velocity loop on an 
                      haptic device, with the aid of a servo-amplifier and tachometer for motor control. 
                    </div>
                  </p>
                            
              </td>
              </tr>
              
            </tbody></table>

          </div>
