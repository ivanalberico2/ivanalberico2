---
layout: default
---

<!-- <!DOCTYPE html> -->
<html>

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
      .justified-text {
          text-align: justify;
      }
  </style>
  <title>Justified Text Example</title>
</head>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
        <div class="column has-text-centered">
          <h1 align="center" class="title is-1 publication-title"><b>Instinctive Robot Control via Hololens2</b></h1>
          <div class="column is-full_width">
          </div>
          <br>
          <div align="center" class="is-size-5 publication-authors">
                <h5 align="center" class="title is-1 publication-title">
                  <b>
                <a href="https://ivanalberico.github.io/">Ivan Alberico</a></span></span>&nbsp;&nbsp;&nbsp;&nbsp;
              <span class="author-block">
              <a href="https://www.linkedin.com/in/michael--baumgartner/?originalSubdomain=ch">Michael Baumgartner</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
              </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/jonathan-becker-tech/">Jonathan Becker</a></span></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://www.linkedin.com/in/seif-ismail-143b53247/">Seif Ismail</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
            </span>
            </b>
            <br><br>
            <span class="author-block"><a href="https://cvg.ethz.ch/">Computer Vision and Geometry LAB, ETH Zurich</a></span>
            </h5>
          </div>
          </div>
        </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <br><hr>
      <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <br>
        <h2 align="center" class="title is-3"><b>Abstract</b></h2>
        <div class="content has-text-justified">
          <p class="justified-text">
            The objective of this project revolves around the development of an 
            immersive mixed reality interface for the Microsoft HoloLens 2 (HL2). 
            The end goal is to empower users to remotely control a robotic arm, facilitating 
            the execution of fundamental assembly tasks through a combination of hand and eye 
            tracking. The integration of C#, Unity, and the Mixed Reality Toolkit (MRTK) is 
            instrumental in crafting an intuitive interface that seamlessly interfaces with 
            the Hololens 2.

          </p>

          <br>
          <video autoplay loop muted src="assets/img/mixedreality_demo-project.mp4" alt="sym" width="100%" style="margin-top:10px;padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black"></video>
          <br>
          <br>
          <br>

          <p class="justified-text">
            As a pivotal element of this project, the Robot Operating System (ROS) takes 
            center stage in establishing communication between the mixed reality interface 
            and the physical robotic arm. This integration enables users to exert control 
            over the robotic arm from a remote location, thereby facilitating a versatile 
            and user-friendly experience.

            Within the realm of object pose estimation, Python and OpenCV come into play, 
            leveraging the distinctive qualities of ArUco markers as fiducial markers. This 
            pairing of technologies allows for the accurate determination of the poses of 
            physical objects in the tangible environment, a prerequisite for the successful 
            execution of assembly tasks.

          </p>
          <br>
        </div>
      </div>
    </div>

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

      <!-- Method -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <hr>
          <br>
          <h2 align="center" class="title is-3"><b>Quaternion Averaging</b></h2>
          <br>
          <div class="content has-text-justified">
            <p class="justified-text">
              However, a critical facet of this project revolves around the nuanced incorporation 
              of quaternion averaging techniques. This intricate process serves a paramount role 
              in refining the accuracy of pose estimation. Specifically, quaternion averaging plays 
              a pivotal role in mitigating jittering and ensuring the fluidity of transitions within 
              the virtual representation of physical objects. This becomes particularly salient in 
              scenarios demanding precision, such as the control of a robotic arm for intricate assembly 
              operations.
              
              The significance of quaternion averaging is underscored by its ability to address tracking 
              inaccuracies and variations in pose estimation that may arise during user interactions within 
              the augmented environment. By effectively managing orientation data, quaternion averaging 
              emerges as a robust solution to instill stability and cohesiveness, ultimately contributing 
              to a seamless and visually satisfying mixed reality experience.
            </p>

            <p class="justified-text">  </p>
            <br>
            <div style="text-align: center;">Without quaternion averaging:</div>
            <video autoplay loop muted src="assets/img/mixedreality_jitterypose.mp4" alt="sym" width="100%" style="margin-top:10px;padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black"></video>
            <br>

            <p class="justified-text"></p>
            <br>
            <div style="text-align: center;">With quaternion averaging:</div>
            <video autoplay loop muted src="assets/img/mixedreality_avgquaternionpose.mp4" alt="sym" width="100%" style="margin-top:10px;padding-top:0px;padding-bottom:0px;border-radius:15px;border:1px solid black"></video>
            <br>

          </div>
        </div>
      </div>


      <!-- Key Idea -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <hr>
          <br>
          <h2 align="center" class="title is-3"><b>Key Idea</b></h2>
          <br> 
          <br>

          <p class="justified-text">
            
            In essence, this comprehensive amalgamation of C#, Unity, MRTK, ROS, Python, and OpenCV as part 
            of this project seeks to yield a fluid, user-centric mixed reality interface for remote robotic 
            arm control. The deliberate emphasis on quaternion averaging is a testament to the commitment to 
            precision and stability, ensuring that the virtual representation aligns seamlessly with the physical 
            reality, and enhancing the overall user experience within the mixed reality environment.
        
          </p>

          <br> 
          <div align="center"><img src="assets/img/mixedreality.jpg" width="60%" class="center"/></div>
          <div class="content has-text-justified">

          </div>
        </div>
      </div>
      <hr>
      

</div>
</section>




</body>
</html>